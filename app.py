"""
URLæ–‡æœ¬è¯é¢‘åˆ†æå¯è§†åŒ–ç³»ç»Ÿ
åŠŸèƒ½ï¼š
1. æŠ“å–æŒ‡å®šURLçš„**æ•´ä¸ªç½‘é¡µ**æ–‡æœ¬å†…å®¹ï¼ˆæ”¯æŒå¤šURLæ‰¹é‡çˆ¬å–ï¼‰
2. ä¸­æ–‡åˆ†è¯ä¸è¯é¢‘ç»Ÿè®¡ï¼ˆè¿‡æ»¤åœç”¨è¯ã€ä½é¢‘è¯ï¼‰
3. åŸºäºPyechartsçš„å¤šå›¾è¡¨å¯è§†åŒ–ï¼ˆ9ç§å›¾è¡¨ï¼‰
4. Streamlitäº¤äº’å¼ç•Œé¢ï¼ˆä¾§è¾¹æ å›¾è¡¨ç­›é€‰ã€ä½é¢‘è¯è¿‡æ»¤ï¼‰
"""

import streamlit as st
import requests
from bs4 import BeautifulSoup
import jieba
import re
from collections import Counter
# å¼•å…¥è‡ªå®šä¹‰æ¨¡å—
import crawler
import text_proc

# Pyechartsç›¸å…³
from pyecharts import options as opts
from pyecharts.charts import WordCloud, Bar, Line, Pie, Radar, Scatter, HeatMap, TreeMap, Polar
from streamlit_echarts import st_pyecharts

# ---------------------- é¡µé¢é…ç½® ----------------------
st.set_page_config(
    page_title="URLæ–‡æœ¬è¯é¢‘åˆ†æç³»ç»Ÿ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------- å…¨å±€å¸¸é‡ ----------------------
# ä¸­æ–‡åœç”¨è¯è¡¨ï¼ˆæ‰©å……ç‰ˆï¼‰
STOP_WORDS = set([
    "çš„", "äº†", "åœ¨", "æ˜¯", "æˆ‘", "æœ‰", "å’Œ", "å°±", "ä¸", "äºº", "éƒ½", "ä¸€", "ä¸€ä¸ª", "ä¸Š", "ä¹Ÿ",
    "å¾ˆ", "åˆ°", "è¯´", "è¦", "å»", "ä½ ", "ä¼š", "ç€", "æ²¡æœ‰", "çœ‹", "å¥½", "è‡ªå·±", "è¿™", "é‚£",
    "ä»–", "å¥¹", "å®ƒ", "æˆ‘ä»¬", "ä½ ä»¬", "ä»–ä»¬", "è¿™é‡Œ", "é‚£é‡Œ", "ç„¶å", "ä½†æ˜¯", "å› ä¸º", "æ‰€ä»¥",
    "å¦‚æœ", "è™½ç„¶", "è¿™äº›", "é‚£äº›", "ä»€ä¹ˆ", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "å“ªä¸ª", "å“ª", "å¤šå°‘", "å‡ ",
    "ä¸", "åŠ", "ç­‰", "å¯¹", "å¯¹äº", "å…³äº", "é€šè¿‡", "ä¸ºäº†", "æ¥è‡ª", "ç”¨äº", "å…¶ä¸­", "åŒ…æ‹¬",
    "å¯ä»¥", "å°†", "èƒ½", "è®©", "ä½¿", "è¢«", "æŠŠ", "ç»™", "å‘", "ä»", "ä»¥", "ä¹‹", "è€Œ", "åˆ™",
    "æ­¤", "è¯¥", "å…¶", "æˆ–", "å³", "å› ", "ç”±", "åŠ", "å¹¶", "ä¸ª", "ä½", "ä»¶", "æ¡", "æœ¬", "é¡¹"
])

# ---------------------- æ ¸å¿ƒå‡½æ•° ----------------------
def fetch_url_all_text(url: str) -> str:
    """
    æŠ“å–**æ•´ä¸ªç½‘é¡µ**çš„æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼ˆæ›¿ä»£åŸæ–‡ç« è¯¦æƒ…é¡µæŠ“å–é€»è¾‘ï¼‰
    :param url: ç›®æ ‡ç½‘é¡µURL
    :return: ç½‘é¡µæ‰€æœ‰å¯è§æ–‡æœ¬å†…å®¹
    """
    try:
        # è°ƒç”¨crawler.pyçš„å‡½æ•°è·å–ç½‘é¡µæ–‡æœ¬ï¼ˆç»Ÿä¸€çˆ¬å–é€»è¾‘ï¼‰
        html_content = crawler.get_web_page(url)
        if not html_content:
            st.error(f"æ— æ³•è·å–{url}çš„ç½‘é¡µå†…å®¹")
            return ""
        # è°ƒç”¨crawler.pyçš„è§£æå‡½æ•°æå–å®Œæ•´æ–‡æœ¬
        full_text = crawler.parse_page(html_content)
        if not full_text:
            st.warning(f"æœªä»{url}ä¸­æå–åˆ°æœ‰æ•ˆæ–‡æœ¬")
            return ""
        return full_text
    except Exception as e:
        st.error(f"æŠ“å–{url}å¤±è´¥ï¼š{str(e)}")
        return ""

def process_text_for_freq(text: str, min_freq: int) -> tuple:
    """
    æ–‡æœ¬å¤„ç†ä¸è¯é¢‘ç»Ÿè®¡ï¼ˆæ•´åˆtext_proc.pyçš„é€»è¾‘ï¼‰
    :param text: åŸå§‹æ–‡æœ¬
    :param min_freq: æœ€å°è¯é¢‘é˜ˆå€¼
    :return: (top20_words, word_freq)
    """
    # è°ƒç”¨text_proc.pyçš„æ¸…æ´—å‡½æ•°
    text_without_html = text_proc.remove_html_tags(text)
    clean_text = text_proc.remove_punctuation(text_without_html)
    # åˆ†è¯ï¼ˆåŠ å…¥åœç”¨è¯è¿‡æ»¤ï¼‰
    words = jieba.lcut(clean_text)
    valid_words = [
        word for word in words
        if len(word) > 1 
        and word not in STOP_WORDS 
        and not word.isdigit()
    ]
    # ç»Ÿè®¡è¯é¢‘
    word_counter = Counter(valid_words)
    filtered_counter = Counter({k: v for k, v in word_counter.items() if v >= min_freq})
    top20_words = filtered_counter.most_common(20)
    return top20_words, filtered_counter

# ---------------------- ä¾§è¾¹æ ï¼šå›¾è¡¨ç­›é€‰ ----------------------
st.sidebar.title("ğŸ“Š å¯è§†åŒ–å›¾è¡¨ç­›é€‰")
chart_type = st.sidebar.selectbox(
    "é€‰æ‹©å›¾è¡¨ç±»å‹",
    options=[
        "è¯äº‘å›¾", "è¯é¢‘å‰20æŸ±çŠ¶å›¾", "è¯é¢‘å‰20æŠ˜çº¿å›¾", "è¯é¢‘å‰20é¥¼å›¾",
        "è¯é¢‘é›·è¾¾å›¾", "è¯é¢‘æ•£ç‚¹å›¾", "è¯é¢‘çƒ­åŠ›å›¾", "è¯é¢‘æ ‘çŠ¶å›¾", "è¯é¢‘æåæ ‡å›¾"
    ],
    index=0
)

# ---------------------- ä¸»é¡µé¢ï¼šè¾“å…¥ä¸åˆ†æ ----------------------
st.title("ğŸ” URLæ–‡æœ¬è¯é¢‘åˆ†æå¯è§†åŒ–ç³»ç»Ÿ")
st.markdown("### è¯·è¾“å…¥ç½‘é¡µURLï¼Œä¸€é”®åˆ†æ**æ•´ç«™æ–‡æœ¬**è¯é¢‘å¹¶å¯è§†åŒ–")

# 1. å¤šURLè¾“å…¥æ”¯æŒï¼ˆé€‚é…æ•´ç«™å¤šé¡µé¢çˆ¬å–ï¼‰
url_count = st.number_input("è¦åˆ†æçš„URLæ•°é‡", min_value=1, max_value=5, value=1, step=1)
urls = []
for i in range(url_count):
    url = st.text_input(
        f"ç½‘é¡µURL {i+1}", 
        value="", 
        placeholder="ä¾‹å¦‚ï¼šhttps://uiaec.ujs.edu.cn/news_list.php?parentid=4/"
    )
    urls.append(url)

# 2. ä½é¢‘è¯è¿‡æ»¤æ»‘åŠ¨æ¡
min_freq = st.slider("è¿‡æ»¤ä½é¢‘è¯ï¼ˆæœ€å°è¯é¢‘ï¼‰", min_value=1, max_value=10, value=2, step=1)

# 3. åˆ†ææŒ‰é’®
if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
    # è¿‡æ»¤ç©ºURL
    valid_urls = [url.strip() for url in urls if url.strip()]
    if not valid_urls:
        st.warning("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„URL")
    else:
        with st.spinner("æ­£åœ¨æŠ“å–ç½‘é¡µå¹¶åˆ†æ..."):
            # æ‰¹é‡æŠ“å–æ‰€æœ‰URLçš„æ–‡æœ¬
            all_text = ""
            for url in valid_urls:
                text = fetch_url_all_text(url)
                all_text += text + "\n"
            
            if not all_text.strip():
                st.warning("æœªæŠ“å–åˆ°ä»»ä½•æœ‰æ•ˆæ–‡æœ¬")
                st.stop()
            
            # å¤„ç†æ–‡æœ¬å¹¶ç»Ÿè®¡è¯é¢‘
            top20_words, word_freq = process_text_for_freq(all_text, min_freq)
            
            if not word_freq:
                st.warning(f"æ— æ»¡è¶³æœ€å°è¯é¢‘{min_freq}çš„è¯æ±‡ï¼Œè¯·é™ä½é˜ˆå€¼")
                st.stop()
            
            # è°ƒç”¨text_proc.pyä¿å­˜è¯é¢‘ç»“æœ
            text_proc.save_word_freq_to_file(dict(word_freq), top20_words)
            
            # æå–æ•°æ®ç”¨äºå¯è§†åŒ–
            top20_words_list = [word for word, freq in top20_words]
            top20_freq_list = [freq for word, freq in top20_words]

            # ---------------------- ç»“æœå±•ç¤º ----------------------
            st.success(f"âœ… åˆ†æå®Œæˆï¼å…±æŠ“å–{len(valid_urls)}ä¸ªç½‘é¡µï¼Œç»Ÿè®¡åˆ°{len(word_freq)}ä¸ªæœ‰æ•ˆè¯æ±‡")
            
            # åˆ†ä¸¤åˆ—å±•ç¤ºï¼šè¯é¢‘æ’å + å›¾è¡¨
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.markdown("### ğŸ“ˆ è¯é¢‘å‰20æ’å")
                for idx, (word, freq) in enumerate(top20_words, 1):
                    st.write(f"{idx}. **{word}** - {freq}æ¬¡")
            
            with col2:
                st.markdown(f"### ğŸ“Š {chart_type}")
                # æ ¹æ®é€‰æ‹©çš„å›¾è¡¨ç±»å‹ç”Ÿæˆå¯¹åº”å›¾è¡¨
                if chart_type == "è¯äº‘å›¾":
                    wordcloud_data = list(word_freq.items())
                    wc = (
                        WordCloud()
                        .add("", wordcloud_data, word_size_range=[20, 100], shape="circle")
                        .set_global_opts(title_opts=opts.TitleOpts(title="æ–‡æœ¬è¯äº‘å›¾", pos_left="center"))
                    )
                    st_pyecharts(wc, width="100%", height="500px")
                
                elif chart_type == "è¯é¢‘å‰20æŸ±çŠ¶å›¾":
                    bar = (
                        Bar()
                        .add_xaxis(top20_words_list)
                        .add_yaxis("è¯é¢‘", top20_freq_list)
                        .reversal_axis()
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title="è¯é¢‘å‰20æŸ±çŠ¶å›¾", pos_left="center"),
                            xaxis_opts=opts.AxisOpts(name="è¯é¢‘"),
                            yaxis_opts=opts.AxisOpts(name="è¯æ±‡")
                        )
                    )
                    st_pyecharts(bar, width="100%", height="500px")
                
                elif chart_type == "è¯é¢‘å‰20æŠ˜çº¿å›¾":
                    line = (
                        Line()
                        .add_xaxis(top20_words_list)
                        .add_yaxis("è¯é¢‘", top20_freq_list, is_smooth=True)
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title="è¯é¢‘å‰20æŠ˜çº¿å›¾", pos_left="center"),
                            xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=-30))
                        )
                    )
                    st_pyecharts(line, width="100%", height="500px")
                
                elif chart_type == "è¯é¢‘å‰20é¥¼å›¾":
                    pie = (
                        Pie()
                        .add("", top20_words)
                        .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘å‰20é¥¼å›¾", pos_left="center"))
                        .set_series_opts(label_opts=opts.LabelOpts(formatter="{b}: {c}"))
                    )
                    st_pyecharts(pie, width="100%", height="500px")
                
                elif chart_type == "è¯é¢‘é›·è¾¾å›¾":
                    radar_words = top20_words_list[:10]
                    radar_freq = top20_freq_list[:10]
                    if radar_freq:
                        radar = (
                            Radar()
                            .add_schema(schema=[opts.RadarIndicatorItem(name=word, max_=max(radar_freq)) for word in radar_words])
                            .add("è¯é¢‘", [radar_freq])
                            .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘å‰10é›·è¾¾å›¾", pos_left="center"))
                        )
                        st_pyecharts(radar, width="100%", height="500px")
                
                elif chart_type == "è¯é¢‘æ•£ç‚¹å›¾":
                    scatter = (
                        Scatter()
                        .add_xaxis(top20_words_list)
                        .add_yaxis("è¯é¢‘", top20_freq_list)
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title="è¯é¢‘å‰20æ•£ç‚¹å›¾", pos_left="center"),
                            xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate=-30))
                        )
                    )
                    st_pyecharts(scatter, width="100%", height="500px")
                
                elif chart_type == "è¯é¢‘çƒ­åŠ›å›¾":
                    heatmap_data = [[0, idx, freq] for idx, freq in enumerate(top20_freq_list)]
                    heatmap = (
                        HeatMap()
                        .add_xaxis(top20_words_list)
                        .add_yaxis("è¯é¢‘", [" "], heatmap_data)
                        .set_global_opts(
                            title_opts=opts.TitleOpts(title="è¯é¢‘å‰20çƒ­åŠ›å›¾", pos_left="center"),
                            visualmap_opts=opts.VisualMapOpts(min_=min(top20_freq_list), max_=max(top20_freq_list))
                        )
                    )
                    st_pyecharts(heatmap, width="100%", height="300px")
                
                elif chart_type == "è¯é¢‘æ ‘çŠ¶å›¾":
                    treemap_data = [{"name": k, "value": v} for k, v in top20_words]
                    treemap = (
                        TreeMap()
                        .add("", treemap_data)
                        .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘å‰20æ ‘çŠ¶å›¾", pos_left="center"))
                        .set_series_opts(label_opts=opts.LabelOpts(formatter="{b}: {c}"))
                    )
                    st_pyecharts(treemap, width="100%", height="500px")
                
                elif chart_type == "è¯é¢‘æåæ ‡å›¾":
                    polar_words = top20_words_list[:10]
                    polar_freq = top20_freq_list[:10]
                    if polar_freq:
                        polar = (
                            Polar()
                            .add_schema(angleaxis_opts=opts.AngleAxisOpts(data=polar_words, type_="category"))
                            .add("è¯é¢‘", polar_freq, type_="bar")
                            .set_global_opts(title_opts=opts.TitleOpts(title="è¯é¢‘å‰10æåæ ‡å›¾", pos_left="center"))
                        )
                        st_pyecharts(polar, width="100%", height="500px")

# ---------------------- ä¾§è¾¹æ è¯´æ˜ ----------------------
st.sidebar.markdown("---")
st.sidebar.markdown("#### ğŸ“ ä½¿ç”¨è¯´æ˜")
st.sidebar.markdown("1. è¾“å…¥**ä»»æ„ç½‘é¡µURL**ï¼ˆæ”¯æŒå¤šä¸ªURLæ‰¹é‡åˆ†æï¼‰")
st.sidebar.markdown("2. è°ƒæ•´æ»‘åŠ¨æ¡è®¾ç½®æœ€å°è¯é¢‘é˜ˆå€¼")
st.sidebar.markdown("3. ç‚¹å‡»ã€Œå¼€å§‹åˆ†æã€æŸ¥çœ‹æ•´ç«™æ–‡æœ¬çš„è¯é¢‘ç»“æœ")
st.sidebar.markdown("4. ä¾§è¾¹æ åˆ‡æ¢ä¸åŒå›¾è¡¨ç±»å‹")